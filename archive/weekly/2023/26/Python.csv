id,name,full_name,language,new stars,description,forks_count,stargazers_count,avatar_url
83222441,system-design-primer,donnemartin/system-design-primer,Python,566,Learn how to design large-scale systems. Prep for the system design interview.  Includes Anki flashcards.,39498,223101,https://avatars.githubusercontent.com/u/5458997?u=f1007b583e55e7ccfb6ccf0e200051156112dd9b&v=4
843222,scikit-learn,scikit-learn/scikit-learn,Python,270,scikit-learn: machine learning in Python,24405,54912,https://avatars.githubusercontent.com/u/365630?v=4
634224458,gpt-engineer,AntonOsika/gpt-engineer,Python,11557,"Specify what you want it to build, the AI asks for clarification, and then builds it.",5639,33935,https://avatars.githubusercontent.com/u/4467025?u=c2388ec6b40a2c362b274741158ccafed41ce4c4&v=4
569927055,stablediffusion,Stability-AI/stablediffusion,Python,776,High-Resolution Image Synthesis with Latent Diffusion Models,3283,25786,https://avatars.githubusercontent.com/u/100950301?v=4
642323624,DragGAN,XingangPan/DragGAN,Python,5707,Official Code for DragGAN (SIGGRAPH 2023),2311,25347,https://avatars.githubusercontent.com/u/13579537?u=d3436a58b7f07f60d1ddd0e30e33e9c1f0b5e331&v=4
580642043,text-generation-webui,oobabooga/text-generation-webui,Python,598,"A gradio web UI for running Large Language Models like LLaMA, llama.cpp, GPT-J, Pythia, OPT, and GALACTICA.",2053,16281,https://avatars.githubusercontent.com/u/112222186?u=b632bfe07653fcd5b3a4345703d06877e5005805&v=4
305144746,tinygrad,geohot/tinygrad,Python,1161,You like pytorch? You like micrograd? You love tinygrad! ❤️ ,1674,15343,https://avatars.githubusercontent.com/u/72895?u=64c16e3f87c708f1f3920331f1f6285f6529960e&v=4
41179827,discord.py,Rapptz/discord.py,Python,128,An API wrapper for Discord written in Python.,3728,13127,https://avatars.githubusercontent.com/u/1695103?v=4
330914717,ivy,unifyai/ivy,Python,306,Unified AI,4477,11599,https://avatars.githubusercontent.com/u/63879146?v=4
167694194,frigate,blakeblackshear/frigate,Python,95,NVR with realtime local object detection for IP cameras,863,8526,https://avatars.githubusercontent.com/u/569905?u=a454086144f531389a73fbea93a7835eea06f2a1&v=4
619825247,LMFlow,OptimalScale/LMFlow,Python,548,An Extensible Toolkit for Finetuning and Inference of Large Foundation Models. Large Model for All.,973,6589,https://avatars.githubusercontent.com/u/128913633?v=4
414545335,stylegan3,NVlabs/stylegan3,Python,223,Official PyTorch implementation of StyleGAN3,971,5505,https://avatars.githubusercontent.com/u/2695301?v=4
629749002,OpenLLM,bentoml/OpenLLM,Python,1577,"An open platform for operating large language models (LLMs) in production. Fine-tune, serve, deploy, and monitor any LLMs with ease.",284,4538,https://avatars.githubusercontent.com/u/49176046?v=4
416157128,composer,mosaicml/composer,Python,80,Train neural networks up to 7x faster,266,3728,https://avatars.githubusercontent.com/u/75143706?v=4
654905384,infinigen,princeton-vl/infinigen,Python,1624,Infinite Photorealistic Worlds using Procedural Generation,362,3579,https://avatars.githubusercontent.com/u/29677746?v=4
631580207,WizardLM,nlpxucan/WizardLM,Python,513,"Family of instruction-following LLMs powered by Evol-Instruct: WizardLM, WizardCoder",255,3499,https://avatars.githubusercontent.com/u/12636990?u=72c8357874bc1abed76e09d111025f9cde0c1806&v=4
634046345,llm-foundry,mosaicml/llm-foundry,Python,189,LLM training code for MosaicML foundation models,230,2417,https://avatars.githubusercontent.com/u/75143706?v=4
629142696,h2o-llmstudio,h2oai/h2o-llmstudio,Python,166,H2O LLM Studio - a framework and no-code GUI for fine-tuning LLMs,177,1959,https://avatars.githubusercontent.com/u/1402695?v=4
625274957,ChatGLM-Efficient-Tuning,hiyouga/ChatGLM-Efficient-Tuning,Python,192,Fine-tuning ChatGLM-6B with PEFT | 基于 PEFT 的高效 ChatGLM 微调,178,1526,https://avatars.githubusercontent.com/u/16256802?u=9622ad4c25aa0a0bfc6dfac3db6bd0d7732c0f1e&v=4
655105480,sd-webui-roop,s0md3v/sd-webui-roop,Python,738,roop extension for StableDiffusion web-ui,227,992,https://avatars.githubusercontent.com/u/26716802?u=51ee13ab4744b9215b6c97974a741906ff47aa07&v=4
646410686,LLaMA-Efficient-Tuning,hiyouga/LLaMA-Efficient-Tuning,Python,204,Fine-tuning LLaMA with PEFT (PT+SFT+RLHF with QLoRA),479,982,https://avatars.githubusercontent.com/u/16256802?u=9622ad4c25aa0a0bfc6dfac3db6bd0d7732c0f1e&v=4
617708951,autolabel,refuel-ai/autolabel,Python,460,"Label, clean and enrich text datasets with LLMs. Discord: https://discord.gg/fweVnRx6CU",52,933,https://avatars.githubusercontent.com/u/88293968?v=4
616179530,sd-webui-text2video,kabachuha/sd-webui-text2video,Python,85,Auto1111 extension implementing text2video diffusion models (like ModelScope or VideoCrafter) using only Auto1111 webui dependencies,57,847,https://avatars.githubusercontent.com/u/14872007?u=ef34b7d1c641418eea985762dae1fb3936569c34&v=4
646488027,WebGLM,THUDM/WebGLM,Python,431,WebGLM: An Efficient Web-enhanced Question Answering System (KDD 2023),77,803,https://avatars.githubusercontent.com/u/48590610?v=4
636467087,exllama,turboderp/exllama,Python,188,A more memory-efficient rewrite of the HF transformers implementation of Llama for use with quantized weights.,63,735,https://avatars.githubusercontent.com/u/11859846?u=9edfe1b9984e47b374f503ae200802d1039c0026&v=4
