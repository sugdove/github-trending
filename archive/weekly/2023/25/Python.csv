id,name,full_name,language,new stars,description,forks_count,stargazers_count,avatar_url
83222441,system-design-primer,donnemartin/system-design-primer,Python,530,Learn how to design large-scale systems. Prep for the system design interview.  Includes Anki flashcards.,39451,222830,https://avatars.githubusercontent.com/u/5458997?u=f1007b583e55e7ccfb6ccf0e200051156112dd9b&v=4
843222,scikit-learn,scikit-learn/scikit-learn,Python,191,scikit-learn: machine learning in Python,24399,54845,https://avatars.githubusercontent.com/u/365630?v=4
552661142,langchain,hwchase17/langchain,Python,1645,âš¡ Building applications with LLMs through composability âš¡,6240,50160,https://avatars.githubusercontent.com/u/11986836?u=f4c4f21a82b2af6c9f91e1f1d99ea40062f7a101&v=4
634224458,gpt-engineer,AntonOsika/gpt-engineer,Python,20344,"Specify what you want it to build, the AI asks for clarification, and then builds it.",5170,31970,https://avatars.githubusercontent.com/u/4467025?u=c2388ec6b40a2c362b274741158ccafed41ce4c4&v=4
580642043,text-generation-webui,oobabooga/text-generation-webui,Python,556,"A gradio web UI for running Large Language Models like LLaMA, llama.cpp, GPT-J, Pythia, OPT, and GALACTICA.",1999,15988,https://avatars.githubusercontent.com/u/112222186?u=b632bfe07653fcd5b3a4345703d06877e5005805&v=4
305144746,tinygrad,geohot/tinygrad,Python,1167,You like pytorch? You like micrograd? You love tinygrad! â¤ï¸ ,1654,15205,https://avatars.githubusercontent.com/u/72895?u=64c16e3f87c708f1f3920331f1f6285f6529960e&v=4
330914717,ivy,unifyai/ivy,Python,199,Unified AI,4416,11481,https://avatars.githubusercontent.com/u/63879146?v=4
574506496,chatgpt-mirai-qq-bot,lss233/chatgpt-mirai-qq-bot,Python,357,ğŸš€ ä¸€é”®éƒ¨ç½²ï¼çœŸæ­£çš„ AI èŠå¤©æœºå™¨äººï¼æ”¯æŒChatGPTã€æ–‡å¿ƒä¸€è¨€ã€è®¯é£æ˜Ÿç«ã€Bingã€Bardã€ChatGLMã€POEï¼Œå¤šè´¦å·ï¼Œäººè®¾è°ƒæ•™ï¼Œè™šæ‹Ÿå¥³ä»†ã€å›¾ç‰‡æ¸²æŸ“ã€è¯­éŸ³å‘é€ | æ”¯æŒ QQã€Telegramã€Discordã€å¾®ä¿¡ ç­‰å¹³å°,1043,7780,https://avatars.githubusercontent.com/u/8984680?u=e4d7e61d39e149291469ba6d5f09532595ad84e3&v=4
619825247,LMFlow,OptimalScale/LMFlow,Python,543,An Extensible Toolkit for Finetuning and Inference of Large Foundation Models. Large Model for All.,955,6334,https://avatars.githubusercontent.com/u/128913633?v=4
203999962,mmagic,open-mmlab/mmagic,Python,249,"OpenMMLab Multimodal Advanced, Generative, and Intelligent Creation Toolbox. Unlock the magic ğŸª„: Generative-AI (AIGC), easy-to-use APIs, awsome model zoo, diffusion models, for text-to-image generation, image/video restoration/enhancement, etc.",889,5286,https://avatars.githubusercontent.com/u/10245193?v=4
629749002,OpenLLM,bentoml/OpenLLM,Python,3293,"An open platform for operating large language models (LLMs) in production. Fine-tune, serve, deploy, and monitor any LLMs with ease.",252,4140,https://avatars.githubusercontent.com/u/49176046?v=4
653595084,baichuan-7B,baichuan-inc/baichuan-7B,Python,781,A large-scale 7B pretraining language model developed by BaiChuan-Inc.,397,3810,https://avatars.githubusercontent.com/u/136167093?v=4
631580207,WizardLM,nlpxucan/WizardLM,Python,625,"Family of instruction-following LLMs powered by Evol-Instruct: WizardLM, WizardCoder",243,3339,https://avatars.githubusercontent.com/u/12636990?u=72c8357874bc1abed76e09d111025f9cde0c1806&v=4
432652408,super-gradients,Deci-AI/super-gradients,Python,238,Easily train or fine-tune SOTA computer vision models with one open source training library. The home of Yolo-NAS.,282,3010,https://avatars.githubusercontent.com/u/56918593?v=4
618613272,h2ogpt,h2oai/h2ogpt,Python,530,"Join us at H2O.ai to make the world's best open-source GPT with document and image Q&A, 100% private chat, no data leaks, Apache 2.0 https://arxiv.org/pdf/2306.08161.pdf",258,2920,https://avatars.githubusercontent.com/u/1402695?v=4
363765247,KoboldAI-Client,KoboldAI/KoboldAI-Client,Python,53,,415,2408,https://avatars.githubusercontent.com/u/83558899?u=21bd39dbb9ee2023d321194e2f5baf88380f27ab&v=4
652668626,ijepa,facebookresearch/ijepa,Python,407,"Official codebase for I-JEPA, the Image-based Joint-Embedding Predictive Architecture. First outlined in the CVPR paper, ""Self-supervised learning from images with a joint-embedding predictive architecture.""",327,1883,https://avatars.githubusercontent.com/u/16943930?v=4
629142696,h2o-llmstudio,h2oai/h2o-llmstudio,Python,114,H2O LLM Studio - a framework and no-code GUI for fine-tuning LLMs,162,1835,https://avatars.githubusercontent.com/u/1402695?v=4
636372163,lit-gpt,Lightning-AI/lit-gpt,Python,267,"Implementation of Falcon, StableLM, Pythia, INCITE language models based on nanoGPT. Supports flash attention, Int8 and GPTQ 4bit quantization, LoRA and LLaMA-Adapter fine-tuning, pre-training. Apache 2.0-licensed.",122,1396,https://avatars.githubusercontent.com/u/58386951?v=4
595921199,Jenkins-Zero-To-Hero,iam-veeramalla/Jenkins-Zero-To-Hero,Python,83,"Install Jenkins, configure Docker as slave, set up cicd, deploy applications to k8s using Argo CD in GitOps way.",2030,1277,https://avatars.githubusercontent.com/u/43399466?u=90b6b89e88ef573e06a59eef23e2703911f37a88&v=4
637237273,simpleaichat,minimaxir/simpleaichat,Python,438,"Python package for easily interfacing with chat apps, with robust features and minimal code complexity.",38,1004,https://avatars.githubusercontent.com/u/2179708?u=fa33a847bd260bee190d2994538a1ca32d467445&v=4
646410686,LLaMA-Efficient-Tuning,hiyouga/LLaMA-Efficient-Tuning,Python,366,Fine-tuning LLaMA with PEFT (PT+SFT+RLHF with QLoRA),467,878,https://avatars.githubusercontent.com/u/16256802?u=9622ad4c25aa0a0bfc6dfac3db6bd0d7732c0f1e&v=4
646488027,WebGLM,THUDM/WebGLM,Python,329,WebGLM: An Efficient Web-enhanced Question Answering System (KDD 2023),54,641,https://avatars.githubusercontent.com/u/48590610?v=4
568912792,azure-open-ai-embeddings-qna,ruoccofabrizio/azure-open-ai-embeddings-qna,Python,33,"A simple web application for a OpenAI-enabled document search. This repo uses Azure OpenAI Service for creating embeddings vectors from documents. For answering the question of a user, it retrieves the most relevant document and then uses GPT-3, GPT-3.5 or GPT-4 to extract the matching answer for the question.",335,524,https://avatars.githubusercontent.com/u/22171838?u=a7c4ea3fcebeafc5e9857727974bf2a3362dafe4&v=4
642830548,ask-multiple-pdfs,alejandro-ao/ask-multiple-pdfs,Python,194,A Langchain app that allows you to chat with multiple PDFs,155,420,https://avatars.githubusercontent.com/u/18406448?v=4
