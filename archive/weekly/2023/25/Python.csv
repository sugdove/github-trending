id,name,full_name,language,new stars,description,forks_count,stargazers_count,avatar_url
83222441,system-design-primer,donnemartin/system-design-primer,Python,534,Learn how to design large-scale systems. Prep for the system design interview.  Includes Anki flashcards.,39445,222790,https://avatars.githubusercontent.com/u/5458997?u=f1007b583e55e7ccfb6ccf0e200051156112dd9b&v=4
843222,scikit-learn,scikit-learn/scikit-learn,Python,123,scikit-learn: machine learning in Python,24382,54792,https://avatars.githubusercontent.com/u/365630?v=4
552661142,langchain,hwchase17/langchain,Python,1732,âš¡ Building applications with LLMs through composability âš¡,6212,50015,https://avatars.githubusercontent.com/u/11986836?u=f4c4f21a82b2af6c9f91e1f1d99ea40062f7a101&v=4
634224458,gpt-engineer,AntonOsika/gpt-engineer,Python,21751,"Specify what you want it to build, the AI asks for clarification, and then builds it.",5064,31507,https://avatars.githubusercontent.com/u/4467025?u=c2388ec6b40a2c362b274741158ccafed41ce4c4&v=4
580642043,text-generation-webui,oobabooga/text-generation-webui,Python,550,"A gradio web UI for running Large Language Models like LLaMA, llama.cpp, GPT-J, Pythia, OPT, and GALACTICA.",1990,15946,https://avatars.githubusercontent.com/u/112222186?u=b632bfe07653fcd5b3a4345703d06877e5005805&v=4
305144746,tinygrad,geohot/tinygrad,Python,1186,You like pytorch? You like micrograd? You love tinygrad! â¤ï¸ ,1635,15175,https://avatars.githubusercontent.com/u/72895?u=64c16e3f87c708f1f3920331f1f6285f6529960e&v=4
330914717,ivy,unifyai/ivy,Python,154,Unified AI,4397,11416,https://avatars.githubusercontent.com/u/63879146?v=4
574506496,chatgpt-mirai-qq-bot,lss233/chatgpt-mirai-qq-bot,Python,363,ğŸš€ ä¸€é”®éƒ¨ç½²ï¼çœŸæ­£çš„ AI èŠå¤©æœºå™¨äººï¼æ”¯æŒChatGPTã€æ–‡å¿ƒä¸€è¨€ã€è®¯é£æ˜Ÿç«ã€Bingã€Bardã€ChatGLMã€POEï¼Œå¤šè´¦å·ï¼Œäººè®¾è°ƒæ•™ï¼Œè™šæ‹Ÿå¥³ä»†ã€å›¾ç‰‡æ¸²æŸ“ã€è¯­éŸ³å‘é€ | æ”¯æŒ QQã€Telegramã€Discordã€å¾®ä¿¡ ç­‰å¹³å°,1040,7771,https://avatars.githubusercontent.com/u/8984680?u=e4d7e61d39e149291469ba6d5f09532595ad84e3&v=4
619825247,LMFlow,OptimalScale/LMFlow,Python,537,An Extensible Toolkit for Finetuning and Inference of Large Foundation Models. Large Model for All.,955,6304,https://avatars.githubusercontent.com/u/128913633?v=4
203999962,mmagic,open-mmlab/mmagic,Python,346,"OpenMMLab Multimodal Advanced, Generative, and Intelligent Creation Toolbox. Unlock the magic ğŸª„: Generative-AI (AIGC), easy-to-use APIs, awsome model zoo, diffusion models, for text-to-image generation, image/video restoration/enhancement, etc.",889,5281,https://avatars.githubusercontent.com/u/10245193?v=4
629749002,OpenLLM,bentoml/OpenLLM,Python,3159,"An open platform for operating large language models (LLMs) in production. Fine-tune, serve, deploy, and monitor any LLMs with ease.",248,4070,https://avatars.githubusercontent.com/u/49176046?v=4
653595084,baichuan-7B,baichuan-inc/baichuan-7B,Python,957,A large-scale 7B pretraining language model developed by BaiChuan-Inc.,394,3765,https://avatars.githubusercontent.com/u/136167093?v=4
631580207,WizardLM,nlpxucan/WizardLM,Python,678,"Family of instruction-following LLMs powered by Evol-Instruct: WizardLM, WizardCoder",241,3288,https://avatars.githubusercontent.com/u/12636990?u=72c8357874bc1abed76e09d111025f9cde0c1806&v=4
432652408,super-gradients,Deci-AI/super-gradients,Python,229,Easily train or fine-tune SOTA computer vision models with one open source training library. The home of Yolo-NAS.,280,3004,https://avatars.githubusercontent.com/u/56918593?v=4
618613272,h2ogpt,h2oai/h2ogpt,Python,562,"Join us at H2O.ai to make the world's best open-source GPT with document and image Q&A, 100% private chat, no data leaks, Apache 2.0 https://arxiv.org/pdf/2306.08161.pdf",254,2899,https://avatars.githubusercontent.com/u/1402695?v=4
363765247,KoboldAI-Client,KoboldAI/KoboldAI-Client,Python,53,,409,2403,https://avatars.githubusercontent.com/u/83558899?u=21bd39dbb9ee2023d321194e2f5baf88380f27ab&v=4
652668626,ijepa,facebookresearch/ijepa,Python,558,"Official codebase for I-JEPA, the Image-based Joint-Embedding Predictive Architecture. First outlined in the CVPR paper, ""Self-supervised learning from images with a joint-embedding predictive architecture.""",327,1877,https://avatars.githubusercontent.com/u/16943930?v=4
629142696,h2o-llmstudio,h2oai/h2o-llmstudio,Python,107,H2O LLM Studio - a framework and no-code GUI for fine-tuning LLMs,162,1833,https://avatars.githubusercontent.com/u/1402695?v=4
636372163,lit-gpt,Lightning-AI/lit-gpt,Python,282,"Implementation of Falcon, StableLM, Pythia, INCITE language models based on nanoGPT. Supports flash attention, Int8 and GPTQ 4bit quantization, LoRA and LLaMA-Adapter fine-tuning, pre-training. Apache 2.0-licensed.",115,1383,https://avatars.githubusercontent.com/u/58386951?v=4
595921199,Jenkins-Zero-To-Hero,iam-veeramalla/Jenkins-Zero-To-Hero,Python,85,"Install Jenkins, configure Docker as slave, set up cicd, deploy applications to k8s using Argo CD in GitOps way.",2021,1275,https://avatars.githubusercontent.com/u/43399466?u=90b6b89e88ef573e06a59eef23e2703911f37a88&v=4
637237273,simpleaichat,minimaxir/simpleaichat,Python,436,"Python package for easily interfacing with chat apps, with robust features and minimal code complexity.",38,999,https://avatars.githubusercontent.com/u/2179708?u=fa33a847bd260bee190d2994538a1ca32d467445&v=4
646410686,LLaMA-Efficient-Tuning,hiyouga/LLaMA-Efficient-Tuning,Python,458,Fine-tuning LLaMA with PEFT (PT+SFT+RLHF with QLoRA),464,854,https://avatars.githubusercontent.com/u/16256802?u=9622ad4c25aa0a0bfc6dfac3db6bd0d7732c0f1e&v=4
646488027,WebGLM,THUDM/WebGLM,Python,323,WebGLM: An Efficient Web-enhanced Question Answering System (KDD 2023),51,574,https://avatars.githubusercontent.com/u/48590610?v=4
568912792,azure-open-ai-embeddings-qna,ruoccofabrizio/azure-open-ai-embeddings-qna,Python,36,"A simple web application for a OpenAI-enabled document search. This repo uses Azure OpenAI Service for creating embeddings vectors from documents. For answering the question of a user, it retrieves the most relevant document and then uses GPT-3, GPT-3.5 or GPT-4 to extract the matching answer for the question.",335,525,https://avatars.githubusercontent.com/u/22171838?u=a7c4ea3fcebeafc5e9857727974bf2a3362dafe4&v=4
642830548,ask-multiple-pdfs,alejandro-ao/ask-multiple-pdfs,Python,189,A Langchain app that allows you to chat with multiple PDFs,152,402,https://avatars.githubusercontent.com/u/18406448?v=4
