id,name,full_name,language,new stars,description,forks_count,stargazers_count,avatar_url
77213120,tabby,Eugeny/tabby,TypeScript,1353,A terminal for a more modern age,2783,46398,https://avatars.githubusercontent.com/u/161476?u=4604ee9193de2a5d7ec842bff0e1bce408d63a0a&v=4
620936652,gpt4free,xtekky/gpt4free,Python,15396,"decentralising the Ai Industry, just some language model api's...",2129,17172,https://avatars.githubusercontent.com/u/98614666?u=8d3b76c8c7f47a5a9c02f0371acd4fc6ed3abe86&v=4
628419800,MiniGPT-4,Vision-CAIR/MiniGPT-4,Python,4193,MiniGPT-4: Enhancing Vision-language Understanding with Advanced Large Language Models,1819,17038,https://avatars.githubusercontent.com/u/61346166?v=4
624994625,bark,suno-ai/bark,Python,9836,ğŸ”Š Text-Prompted Generative Audio Model,1169,14831,https://avatars.githubusercontent.com/u/99442120?v=4
630023030,StableLM,Stability-AI/StableLM,Jupyter Notebook,2563,StableLM: Stability AI Language Models,729,13117,https://avatars.githubusercontent.com/u/100950301?v=4
335164964,dataease,dataease/dataease,Java,570,äººäººå¯ç”¨çš„å¼€æºæ•°æ®å¯è§†åŒ–åˆ†æå·¥å…·ã€‚,2052,10607,https://avatars.githubusercontent.com/u/75054108?v=4
628296906,MOSS,OpenLMLab/MOSS,Python,5667,An open-source tool-augmented conversational language model from Fudan University,830,9050,https://avatars.githubusercontent.com/u/127190579?v=4
576642715,bloop,BloopAI/bloop,TypeScript,1783,bloop is a fast code search engine written in Rust.,294,5518,https://avatars.githubusercontent.com/u/75376775?v=4
621799276,langchain-ChatGLM,imClumsyPanda/langchain-ChatGLM,Python,1012,"langchain-ChatGLM, local knowledge based ChatGLM with langchain ï½œ åŸºäºæœ¬åœ°çŸ¥è¯†çš„ ChatGLM é—®ç­”",441,4034,https://avatars.githubusercontent.com/u/5668498?v=4
439447708,atproto,bluesky-social/atproto,TypeScript,584,Social networking technology created by Bluesky,212,3585,https://avatars.githubusercontent.com/u/94650532?v=4
603043526,pandora,pengzhile/pandora,Python,1476,"æ½˜å¤šæ‹‰ï¼Œä¸€ä¸ªè®©ä½ å‘¼å¸é¡ºç•…çš„ChatGPTã€‚Pandora, a ChatGPT that helps you breathe smoothly.",415,3054,https://avatars.githubusercontent.com/u/343491?u=b86e91803d6ebd424b473648ae7b8e738a88d271&v=4
625478728,Inpaint-Anything,geekyutao/Inpaint-Anything,Jupyter Notebook,946,Inpaint anything using Segment Anything and inpainting models.,190,2611,https://avatars.githubusercontent.com/u/30614660?u=ee5829337f66b142f09f2dfa6e09c4711b068a91&v=4
630292680,WebGPT,0hq/WebGPT,JavaScript,1220,Run GPT model on the browser with WebGPU. An implementation of GPT inference in less than ~2000 lines of vanilla Javascript. ,118,2403,https://avatars.githubusercontent.com/u/30643741?u=faee0ca26282cee3e829c36827f3daac47cb2e4a&v=4
608634021,whisper-jax,sanchit-gandhi/whisper-jax,Jupyter Notebook,1177,,163,2243,https://avatars.githubusercontent.com/u/93869735?u=42046fb799e6cbe5b98e54872d55c9cf8d63b3bc&v=4
502863191,Fay,TheRamU/Fay,JavaScript,933,Fayæ˜¯ä¸€ä¸ªå®Œæ•´çš„å¼€æºé¡¹ç›®ï¼ŒåŒ…å«Fayæ§åˆ¶å™¨åŠæ•°å­—äººæ¨¡å‹ï¼Œå¯çµæ´»ç»„åˆå‡ºä¸åŒçš„åº”ç”¨åœºæ™¯ï¼šè™šæ‹Ÿä¸»æ’­ã€ç°åœºæ¨é”€è´§ã€å•†å“å¯¼è´­ã€è¯­éŸ³åŠ©ç†ã€è¿œç¨‹è¯­éŸ³åŠ©ç†ã€æ•°å­—äººäº’åŠ¨ã€æ•°å­—äººé¢è¯•å®˜åŠå¿ƒç†æµ‹è¯„ã€è´¾ç»´æ–¯ã€Herã€‚ å¼€æºé¡¹ç›®ï¼Œéäº§å“è¯•ç”¨ï¼ï¼ï¼,414,2119,https://avatars.githubusercontent.com/u/43772379?u=18346fa547dd3be4166e0e8cfb2ca3983364d818&v=4
629102662,LLaVA,haotian-liu/LLaVA,Python,687,Large Language-and-Vision Assistant built towards multimodal GPT-4 level capabilities.,125,1974,https://avatars.githubusercontent.com/u/6631389?u=3a2ec42d1960bfe57a5b6ac519cfd01bf8382065&v=4
567848636,notebooks,roboflow/notebooks,Jupyter Notebook,722,"Examples and tutorials on using SOTA computer vision models and techniques. Learn everything from old-school ResNet, through YOLO and object-detection transformers like DETR, to the latest models like Grounding DINO and SAM.",277,1939,https://avatars.githubusercontent.com/u/53104118?v=4
613961830,ControlNet-v1-1-nightly,lllyasviel/ControlNet-v1-1-nightly,Python,323,Nightly release of ControlNet 1.1,93,1661,https://avatars.githubusercontent.com/u/19834515?u=4c7144779a6b13904fec478c4e98e676b91516ee&v=4
615869301,LocalAI,go-skynet/LocalAI,Go,1280,":robot: Self-hosted, community-driven simple local OpenAI-compatible API written in go. Can be used as a drop-in replacement for OpenAI, running on CPU with consumer-grade hardware. API for ggml compatible models, for instance: llama.cpp, alpaca.cpp, gpt4all.cpp, vicuna, koala, gpt4all-j, cerebras",67,1649,https://avatars.githubusercontent.com/u/128192713?v=4
629207037,HealthGPT,StanfordBDHG/HealthGPT,Swift,312,Query your Apple Health data with natural language ğŸ’¬ ğŸ©º,109,1279,https://avatars.githubusercontent.com/u/118127024?v=4
621705019,BMTools,OpenBMB/BMTools,Python,716,"Tool Learning for Big Models, Open-Source Solutions of ChatGPT-Plugins",93,1143,https://avatars.githubusercontent.com/u/89920203?v=4
629142696,h2o-llmstudio,h2oai/h2o-llmstudio,Python,474,H2O LLM Studio - a framework and no-code GUI for fine-tuning LLMs,77,985,https://avatars.githubusercontent.com/u/1402695?v=4
619814004,databerry,gmpetrov/databerry,TypeScript,587,The no-code platform for connecting custom data to large language models,106,977,https://avatars.githubusercontent.com/u/4693180?u=8cf781d9099d6e2f2d2caf7612a5c2811ba13ef8&v=4
628630832,Segment-and-Track-Anything,z-x-yang/Segment-and-Track-Anything,Jupyter Notebook,316,"An open-source project dedicated to tracking and segmenting any objects in videos, either automatically or interactively. The primary algorithms utilized include the Segment Anything Model (SAM) for key-frame segmentation and Associating Objects with Transformers (AOT) for efficient tracking and propagation purposes.",97,817,https://avatars.githubusercontent.com/u/57658428?u=d2edd716e9b90c1e516e0ae6d20ff91c4a0298cb&v=4
615256382,gptdeploy,jina-ai/gptdeploy,Python,375,One line to create them all,53,810,https://avatars.githubusercontent.com/u/60539444?v=4
