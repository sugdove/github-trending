id,name,full_name,language,new stars,description,forks_count,stargazers_count,avatar_url
527591471,stable-diffusion-webui,AUTOMATIC1111/stable-diffusion-webui,Python,218,Stable Diffusion web UI,20985,104948,https://avatars.githubusercontent.com/u/20920490?u=8bdc7c9401f507e51b55e558baa8184d4ed30c7d&v=4
307260205,yt-dlp,yt-dlp/yt-dlp,Python,85,A youtube-dl fork with additional features and fixes,4714,57396,https://avatars.githubusercontent.com/u/79589310?v=4
660551251,MetaGPT,geekan/MetaGPT,Python,142,"🌟 The Multi-Agent Framework: Given one line Requirement, return PRD, Design, Tasks, Repo",3244,27592,https://avatars.githubusercontent.com/u/2707039?u=463185951e02a6ba817bf59f549e917b7690348c&v=4
265612440,TTS,coqui-ai/TTS,Python,177,"🐸💬 - a deep learning toolkit for Text-to-Speech, battle-tested in research and production",2267,20240,https://avatars.githubusercontent.com/u/75583352?v=4
621799276,Langchain-Chatchat,chatchat-space/Langchain-Chatchat,Python,117,"Langchain-Chatchat（原Langchain-ChatGLM）基于 Langchain 与 ChatGLM 等语言模型的本地知识库问答 | Langchain-Chatchat (formerly langchain-ChatGLM), local knowledge based LLM (like ChatGLM) QA app with langchain ",2801,16594,https://avatars.githubusercontent.com/u/139558948?v=4
522158088,chatgpt-on-wechat,zhayujie/chatgpt-on-wechat,Python,37,"Wechat robot based on ChatGPT,  which using OpenAI api and itchat library. 使用ChatGPT搭建微信聊天机器人，基于 GPT3.5/GPT4.0/Claude/文心一言/讯飞星火/LinkAI，支持个人微信、公众号、企业微信部署，能处理文本、语音和图片，访问操作系统和互联网，支持基于知识库定制专属机器人。",4823,16376,https://avatars.githubusercontent.com/u/26161723?u=a2d51ccd0b85cc5561f42dfe9219a11577dd6c26&v=4
657895120,ChatGLM2-6B,THUDM/ChatGLM2-6B,Python,36,ChatGLM2-6B: An Open Bilingual Chat LLM | 开源双语对话语言模型,2111,13355,https://avatars.githubusercontent.com/u/48590610?v=4
600798098,sd-webui-controlnet,Mikubill/sd-webui-controlnet,Python,22,WebUI extension for ControlNet,1681,13240,https://avatars.githubusercontent.com/u/31246794?u=4e178acd856f9cf98182fc5edad4013f107250c8&v=4
676676006,Fooocus,lllyasviel/Fooocus,Python,80,Focus on prompting and generating,970,13205,https://avatars.githubusercontent.com/u/19834515?u=4c7144779a6b13904fec478c4e98e676b91516ee&v=4
683892956,ChatDev,OpenBMB/ChatDev,Python,362,Create Customized Software using Natural Language Idea (through LLM-powered Multi-Agent Collaboration),1329,12715,https://avatars.githubusercontent.com/u/89920203?v=4
596516907,DocsGPT,arc53/DocsGPT,Python,1697,"GPT-powered chat for documentation, chat with your documents",1029,11110,https://avatars.githubusercontent.com/u/103419759?v=4
458648791,paperless-ngx,paperless-ngx/paperless-ngx,Python,116,"A community-supported supercharged version of paperless: scan, index and archive all your physical documents",542,10660,https://avatars.githubusercontent.com/u/99562962?v=4
626805178,dify,langgenius/dify,Python,35,"One API for plugins and datasets, one interface for prompt engineering and visual operation, all for creating powerful AI applications.",1285,8833,https://avatars.githubusercontent.com/u/127165244?v=4
679237742,gpt-pilot,Pythagora-io/gpt-pilot,Python,1130,Dev tool that writes scalable apps from scratch while the developer oversees the implementation,559,7271,https://avatars.githubusercontent.com/u/123263103?v=4
627480054,DB-GPT,eosphoros-ai/DB-GPT,Python,22,Revolutionizing Database Interactions with Private LLM Technology,1032,7223,https://avatars.githubusercontent.com/u/140580304?v=4
629102662,LLaVA,haotian-liu/LLaVA,Python,493,Visual Instruction Tuning: Large Language-and-Vision Assistant built towards multimodal GPT-4 level capabilities.,568,6781,https://avatars.githubusercontent.com/u/6631389?u=0eaf5d6e8b2d067f89ef93f4b1c4e3ae049dc461&v=4
674075444,Qwen,QwenLM/Qwen,Python,80,The official repo of Qwen (通义千问) chat & pretrained large language model proposed by Alibaba Cloud.,382,5365,https://avatars.githubusercontent.com/u/141221163?v=4
646410686,LLaMA-Efficient-Tuning,hiyouga/LLaMA-Efficient-Tuning,Python,127,"Easy-to-use LLM fine-tuning framework (LLaMA-2, BLOOM, Falcon, Baichuan, Qwen, ChatGLM2)",940,4783,https://avatars.githubusercontent.com/u/16256802?u=9622ad4c25aa0a0bfc6dfac3db6bd0d7732c0f1e&v=4
662878020,InternLM,InternLM/InternLM,Python,13,InternLM has open-sourced a 7 and 20 billion parameter base models and chat models tailored for practical scenarios and the training system.,267,3340,https://avatars.githubusercontent.com/u/135356492?v=4
660489378,promptflow,microsoft/promptflow,Python,220,"Build high-quality LLM apps - from prototyping, testing to production deployment and monitoring.",218,3016,https://avatars.githubusercontent.com/u/6154722?v=4
685444668,Baichuan2,baichuan-inc/Baichuan2,Python,33,A series of large language models developed by Baichuan Intelligent Technology,133,2371,https://avatars.githubusercontent.com/u/136167093?v=4
691050458,genai-stack,docker/genai-stack,Python,54,Langchain + Docker + Neo4j,59,371,https://avatars.githubusercontent.com/u/5429470?v=4
700919494,glue-factory,cvg/glue-factory,Python,36,Training library for local feature detection and matching,18,258,https://avatars.githubusercontent.com/u/840224?v=4
697405312,ToRA,microsoft/ToRA,Python,42,ToRA is a series of Tool-integrated Reasoning LLM Agents designed to solve challenging mathematical reasoning problems by interacting with tools.,14,234,https://avatars.githubusercontent.com/u/6154722?v=4
697853147,LLM-scientific-feedback,Weixin-Liang/LLM-scientific-feedback,Python,27,Can large language models provide useful feedback on research papers? A large-scale empirical analysis.,21,179,https://avatars.githubusercontent.com/u/32794044?u=fc405525dbfc2ef66d9ed9e8862348f6b853f881&v=4
