id,name,full_name,language,new stars,description,forks_count,stargazers_count,avatar_url
527591471,stable-diffusion-webui,AUTOMATIC1111/stable-diffusion-webui,Python,223,Stable Diffusion web UI,20982,104935,https://avatars.githubusercontent.com/u/20920490?u=8bdc7c9401f507e51b55e558baa8184d4ed30c7d&v=4
307260205,yt-dlp,yt-dlp/yt-dlp,Python,104,A youtube-dl fork with additional features and fixes,4714,57382,https://avatars.githubusercontent.com/u/79589310?v=4
660551251,MetaGPT,geekan/MetaGPT,Python,158,"🌟 The Multi-Agent Framework: Given one line Requirement, return PRD, Design, Tasks, Repo",3244,27584,https://avatars.githubusercontent.com/u/2707039?u=463185951e02a6ba817bf59f549e917b7690348c&v=4
265612440,TTS,coqui-ai/TTS,Python,177,"🐸💬 - a deep learning toolkit for Text-to-Speech, battle-tested in research and production",2267,20227,https://avatars.githubusercontent.com/u/75583352?v=4
621799276,Langchain-Chatchat,chatchat-space/Langchain-Chatchat,Python,116,"Langchain-Chatchat（原Langchain-ChatGLM）基于 Langchain 与 ChatGLM 等语言模型的本地知识库问答 | Langchain-Chatchat (formerly langchain-ChatGLM), local knowledge based LLM (like ChatGLM) QA app with langchain ",2800,16591,https://avatars.githubusercontent.com/u/139558948?v=4
522158088,chatgpt-on-wechat,zhayujie/chatgpt-on-wechat,Python,41,"Wechat robot based on ChatGPT,  which using OpenAI api and itchat library. 使用ChatGPT搭建微信聊天机器人，基于 GPT3.5/GPT4.0/Claude/文心一言/讯飞星火/LinkAI，支持个人微信、公众号、企业微信部署，能处理文本、语音和图片，访问操作系统和互联网，支持基于知识库定制专属机器人。",4823,16374,https://avatars.githubusercontent.com/u/26161723?u=a2d51ccd0b85cc5561f42dfe9219a11577dd6c26&v=4
657895120,ChatGLM2-6B,THUDM/ChatGLM2-6B,Python,34,ChatGLM2-6B: An Open Bilingual Chat LLM | 开源双语对话语言模型,2111,13354,https://avatars.githubusercontent.com/u/48590610?v=4
600798098,sd-webui-controlnet,Mikubill/sd-webui-controlnet,Python,25,WebUI extension for ControlNet,1681,13240,https://avatars.githubusercontent.com/u/31246794?u=4e178acd856f9cf98182fc5edad4013f107250c8&v=4
676676006,Fooocus,lllyasviel/Fooocus,Python,90,Focus on prompting and generating,968,13199,https://avatars.githubusercontent.com/u/19834515?u=4c7144779a6b13904fec478c4e98e676b91516ee&v=4
683892956,ChatDev,OpenBMB/ChatDev,Python,362,Create Customized Software using Natural Language Idea (through LLM-powered Multi-Agent Collaboration),1327,12685,https://avatars.githubusercontent.com/u/89920203?v=4
596516907,DocsGPT,arc53/DocsGPT,Python,1677,"GPT-powered chat for documentation, chat with your documents",1026,11091,https://avatars.githubusercontent.com/u/103419759?v=4
458648791,paperless-ngx,paperless-ngx/paperless-ngx,Python,111,"A community-supported supercharged version of paperless: scan, index and archive all your physical documents",541,10653,https://avatars.githubusercontent.com/u/99562962?v=4
626805178,dify,langgenius/dify,Python,35,"One API for plugins and datasets, one interface for prompt engineering and visual operation, all for creating powerful AI applications.",1285,8833,https://avatars.githubusercontent.com/u/127165244?v=4
679237742,gpt-pilot,Pythagora-io/gpt-pilot,Python,1123,Dev tool that writes scalable apps from scratch while the developer oversees the implementation,554,7223,https://avatars.githubusercontent.com/u/123263103?v=4
627480054,DB-GPT,eosphoros-ai/DB-GPT,Python,16,Revolutionizing Database Interactions with Private LLM Technology,1032,7221,https://avatars.githubusercontent.com/u/140580304?v=4
629102662,LLaVA,haotian-liu/LLaVA,Python,575,Visual Instruction Tuning: Large Language-and-Vision Assistant built towards multimodal GPT-4 level capabilities.,567,6717,https://avatars.githubusercontent.com/u/6631389?u=0eaf5d6e8b2d067f89ef93f4b1c4e3ae049dc461&v=4
674075444,Qwen,QwenLM/Qwen,Python,76,The official repo of Qwen (通义千问) chat & pretrained large language model proposed by Alibaba Cloud.,382,5361,https://avatars.githubusercontent.com/u/141221163?v=4
646410686,LLaMA-Efficient-Tuning,hiyouga/LLaMA-Efficient-Tuning,Python,123,"Easy-to-use LLM fine-tuning framework (LLaMA-2, BLOOM, Falcon, Baichuan, Qwen, ChatGLM2)",940,4782,https://avatars.githubusercontent.com/u/16256802?u=9622ad4c25aa0a0bfc6dfac3db6bd0d7732c0f1e&v=4
662878020,InternLM,InternLM/InternLM,Python,9,InternLM has open-sourced a 7 and 20 billion parameter base models and chat models tailored for practical scenarios and the training system.,266,3335,https://avatars.githubusercontent.com/u/135356492?v=4
660489378,promptflow,microsoft/promptflow,Python,215,"Build high-quality LLM apps - from prototyping, testing to production deployment and monitoring.",216,2994,https://avatars.githubusercontent.com/u/6154722?v=4
685444668,Baichuan2,baichuan-inc/Baichuan2,Python,30,A series of large language models developed by Baichuan Intelligent Technology,133,2370,https://avatars.githubusercontent.com/u/136167093?v=4
691050458,genai-stack,docker/genai-stack,Python,57,Langchain + Docker + Neo4j,59,370,https://avatars.githubusercontent.com/u/5429470?v=4
700919494,glue-factory,cvg/glue-factory,Python,33,Training library for local feature detection and matching,18,257,https://avatars.githubusercontent.com/u/840224?v=4
697405312,ToRA,microsoft/ToRA,Python,31,ToRA is a series of Tool-integrated Reasoning LLM Agents designed to solve challenging mathematical reasoning problems by interacting with tools.,13,224,https://avatars.githubusercontent.com/u/6154722?v=4
697853147,LLM-scientific-feedback,Weixin-Liang/LLM-scientific-feedback,Python,24,Can large language models provide useful feedback on research papers? A large-scale empirical analysis.,20,172,https://avatars.githubusercontent.com/u/32794044?u=fc405525dbfc2ef66d9ed9e8862348f6b853f881&v=4
