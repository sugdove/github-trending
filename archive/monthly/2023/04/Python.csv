id,name,full_name,language,new stars,description,forks_count,stargazers_count,avatar_url
21289110,awesome-python,vinta/awesome-python,Python,5202,"A curated list of awesome Python frameworks, libraries, software and resources",23050,165985,https://avatars.githubusercontent.com/u/652070?u=95b472a9a11b64ee0f74512ad918d762d42c213c&v=4
123458551,Python-100-Days,jackfrued/Python-100-Days,Python,3509,Python - 100å¤©ä»æ–°æ‰‹åˆ°å¤§å¸ˆ,48984,135278,https://avatars.githubusercontent.com/u/7474657?u=902200c2389c203cf2139888e10314845edd2a2a&v=4
155220641,transformers,huggingface/transformers,Python,9038,"ğŸ¤— Transformers: State-of-the-art Machine Learning for Pytorch, TensorFlow, and JAX.",20080,96946,https://avatars.githubusercontent.com/u/25720743?v=4
619959033,gpt4all,nomic-ai/gpt4all,Python,35584,"gpt4all: an ecosystem of open-source chatbots trained on a massive collections of clean assistant data including code, stories and dialogue",3790,35719,https://avatars.githubusercontent.com/u/102670180?v=4
552661142,langchain,hwchase17/langchain,Python,16121,âš¡ Building applications with LLMs through composability âš¡,3491,32716,https://avatars.githubusercontent.com/u/11986836?u=f4c4f21a82b2af6c9f91e1f1d99ea40062f7a101&v=4
616372661,gpt_academic,binary-husky/gpt_academic,Python,26166,ä¸ºGPT/GLMæä¾›å›¾å½¢äº¤äº’ç•Œé¢ï¼Œç‰¹åˆ«ä¼˜åŒ–è®ºæ–‡é˜…è¯»æ¶¦è‰²ä½“éªŒï¼Œæ¨¡å—åŒ–è®¾è®¡æ”¯æŒè‡ªå®šä¹‰å¿«æ·æŒ‰é’®&å‡½æ•°æ’ä»¶ï¼Œæ”¯æŒä»£ç å—è¡¨æ ¼æ˜¾ç¤ºï¼ŒTexå…¬å¼åŒæ˜¾ç¤ºï¼Œæ–°å¢Pythonå’ŒC++é¡¹ç›®å‰–æ&è‡ªè¯‘è§£åŠŸèƒ½ï¼ŒPDF/LaTexè®ºæ–‡ç¿»è¯‘&æ€»ç»“åŠŸèƒ½ï¼Œæ”¯æŒå¹¶è¡Œé—®è¯¢å¤šç§LLMæ¨¡å‹ï¼Œæ”¯æŒæ¸…åchatglmç­‰æœ¬åœ°æ¨¡å‹,3626,31139,https://avatars.githubusercontent.com/u/96192199?u=7f92c746908d3dbac7579e5471b07232f2b53adb&v=4
235860204,DeepSpeed,microsoft/DeepSpeed,Python,13513,"DeepSpeed is a deep learning optimization library that makes distributed training and inference easy, efficient, and effective.",2790,23318,https://avatars.githubusercontent.com/u/6154722?v=4
613349035,ChatGLM-6B,THUDM/ChatGLM-6B,Python,11537,ChatGLM-6B: An Open Bilingual Dialogue Language Model | å¼€æºåŒè¯­å¯¹è¯è¯­è¨€æ¨¡å‹,2617,21729,https://avatars.githubusercontent.com/u/48590610?v=4
566576114,ml-stable-diffusion,apple/ml-stable-diffusion,Python,5722,Stable Diffusion with Core ML on Apple Silicon,529,11816,https://avatars.githubusercontent.com/u/10639145?v=4
580642043,text-generation-webui,oobabooga/text-generation-webui,Python,6440,"A gradio web UI for running Large Language Models like LLaMA, llama.cpp, GPT-J, Pythia, OPT, and GALACTICA.",1154,10928,https://avatars.githubusercontent.com/u/112222186?u=b632bfe07653fcd5b3a4345703d06877e5005805&v=4
618511002,dolly,databrickslabs/dolly,Python,6773,"Databricksâ€™ Dolly, a large language model trained on the Databricks Machine Learning Platform",926,9397,https://avatars.githubusercontent.com/u/49501376?v=4
612139233,so-vits-svc,svc-develop-team/so-vits-svc,Python,4258,SoftVC VITS Singing Voice Conversion,1108,6501,https://avatars.githubusercontent.com/u/127122328?v=4
599320067,langflow,logspace-ai/langflow,Python,3703,"â›“ï¸ LangFlow is a UI for LangChain, designed with react-flow to provide an effortless way to experiment and prototype flows.",443,5732,https://avatars.githubusercontent.com/u/85702467?v=4
521021013,GLM-130B,THUDM/GLM-130B,Python,1967,GLM-130B: An Open Bilingual Pre-Trained Model (ICLR 2023),365,5029,https://avatars.githubusercontent.com/u/48590610?v=4
570384908,peft,huggingface/peft,Python,2472,ğŸ¤— PEFT: State-of-the-art Parameter-Efficient Fine-Tuning.,332,4803,https://avatars.githubusercontent.com/u/25720743?v=4
615861000,wolverine,biobootloader/wolverine,Python,4032,,475,4593,https://avatars.githubusercontent.com/u/128252497?u=91e2459fbced290aeb3222a6377edc608ace8258&v=4
603043526,pandora,pengzhile/pandora,Python,2465,"æ½˜å¤šæ‹‰ï¼Œä¸€ä¸ªè®©ä½ å‘¼å¸é¡ºç•…çš„ChatGPTã€‚Pandora, a ChatGPT that helps you breathe smoothly.",408,2986,https://avatars.githubusercontent.com/u/343491?u=b86e91803d6ebd424b473648ae7b8e738a88d271&v=4
617504730,lit-llama,Lightning-AI/lit-llama,Python,2868,"Implementation of the LLaMA language model based on nanoGPT. Supports flash attention, Int8 and GPTQ 4bit quantization, LoRA and LLaMA-Adapter fine-tuning, pre-training. Apache 2.0-licensed.",180,2916,https://avatars.githubusercontent.com/u/58386951?v=4
569518584,SadTalker,OpenTalker/SadTalker,Python,2149,ï¼ˆCVPR 2023ï¼‰SadTalkerï¼šLearning Realistic 3D Motion Coefficients for Stylized Audio-Driven Single Image Talking Face Animation,403,2830,https://avatars.githubusercontent.com/u/118957706?v=4
617219182,ChatDoctor,Kent0n-Li/ChatDoctor,Python,2267,,286,2605,https://avatars.githubusercontent.com/u/47032063?u=f197a10b4c7f9e85eb5b8eef7690a46a2abd3166&v=4
614922400,ChatGLM-Tuning,mymusise/ChatGLM-Tuning,Python,1296,"ä¸€ç§å¹³ä»·çš„chatgptå®ç°æ–¹æ¡ˆ,  åŸºäºChatGLM-6B + LoRA",276,2261,https://avatars.githubusercontent.com/u/6883957?u=ad0059c0062c56cd9e5d7715a8f2e9805c405e5f&v=4
589743600,chat-langchain,hwchase17/chat-langchain,Python,907,,453,1858,https://avatars.githubusercontent.com/u/11986836?u=f4c4f21a82b2af6c9f91e1f1d99ea40062f7a101&v=4
610307205,GPTQ-for-LLaMa,qwopqwop200/GPTQ-for-LLaMa,Python,723,4 bits quantization of LLaMA using GPTQ,257,1581,https://avatars.githubusercontent.com/u/64115820?v=4
599293758,azure-search-openai-demo,Azure-Samples/azure-search-openai-demo,Python,864,"A sample app for the Retrieval-Augmented Generation pattern running in Azure, using Azure Cognitive Search for retrieval and Azure OpenAI large language models  to power ChatGPT-style and Q&A experiences.",589,1446,https://avatars.githubusercontent.com/u/1844662?v=4
613843974,ChatGLM-webui,Akegarasu/ChatGLM-webui,Python,743,A WebUI for ChatGLM-6B,178,1326,https://avatars.githubusercontent.com/u/36563862?u=9b064695721827e6ebe191a3fa974f9b3f9d9ab4&v=4
