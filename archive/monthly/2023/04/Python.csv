id,name,full_name,language,new stars,description,forks_count,stargazers_count,avatar_url
155220641,transformers,huggingface/transformers,Python,8527,"ü§ó Transformers: State-of-the-art Machine Learning for Pytorch, TensorFlow, and JAX.",19704,94050,https://avatars.githubusercontent.com/u/25720743?v=4
527591471,stable-diffusion-webui,AUTOMATIC1111/stable-diffusion-webui,Python,16788,Stable Diffusion web UI,12191,65621,https://avatars.githubusercontent.com/u/20920490?u=8bdc7c9401f507e51b55e558baa8184d4ed30c7d&v=4
422274596,ColossalAI,hpcaitech/ColossalAI,Python,9674,"Making large AI models cheaper, faster and more accessible",3267,28327,https://avatars.githubusercontent.com/u/88699314?v=4
552661142,langchain,hwchase17/langchain,Python,15706,‚ö° Building applications with LLMs through composability ‚ö°,2701,27608,https://avatars.githubusercontent.com/u/11986836?u=f4c4f21a82b2af6c9f91e1f1d99ea40062f7a101&v=4
235860204,DeepSpeed,microsoft/DeepSpeed,Python,11445,"DeepSpeed is a deep learning optimization library that makes distributed training and inference easy, efficient, and effective.",2476,21194,https://avatars.githubusercontent.com/u/6154722?v=4
612427246,stanford_alpaca,tatsu-lab/stanford_alpaca,Python,12536,"Code and documentation to train Stanford's Alpaca models, and generate the data.",2993,20927,https://avatars.githubusercontent.com/u/61893194?v=4
569927055,stablediffusion,Stability-AI/stablediffusion,Python,5270,High-Resolution Image Synthesis with Latent Diffusion Models,2312,19288,https://avatars.githubusercontent.com/u/100950301?v=4
613349035,ChatGLM-6B,THUDM/ChatGLM-6B,Python,13325,ChatGLM-6BÔºöÂºÄÊ∫êÂèåËØ≠ÂØπËØùËØ≠Ë®ÄÊ®°Âûã  | An Open Bilingual Dialogue Language Model,2162,18455,https://avatars.githubusercontent.com/u/48590610?v=4
560704231,llama_index,jerryjliu/llama_index,Python,5678,LlamaIndex (GPT Index) is a project that provides a central interface to connect your LLM's with external data.,1280,12846,https://avatars.githubusercontent.com/u/4858925?u=eb0717916ba7f9d8b9402d17a22e6f645d0f97c7&v=4
566576114,ml-stable-diffusion,apple/ml-stable-diffusion,Python,5447,Stable Diffusion with Core ML on Apple Silicon,509,11362,https://avatars.githubusercontent.com/u/10639145?v=4
580642043,text-generation-webui,oobabooga/text-generation-webui,Python,6254,"A gradio web UI for running Large Language Models like LLaMA, llama.cpp, GPT-J, Pythia, OPT, and GALACTICA.",916,9521,https://avatars.githubusercontent.com/u/112222186?u=b632bfe07653fcd5b3a4345703d06877e5005805&v=4
611305072,ChatPaper,kaixindelele/ChatPaper,Python,7055,Use ChatGPT to summarize the arXiv papers. ÂÖ®ÊµÅÁ®ãÂä†ÈÄüÁßëÁ†îÔºåÂà©Áî®chatgptËøõË°åËÆ∫ÊñáÊÄªÁªì+Ê∂¶Ëâ≤+ÂÆ°Á®ø+ÂÆ°Á®øÂõûÂ§ç,908,9406,https://avatars.githubusercontent.com/u/28528386?u=f51286c1662d2a7d46c32297ecd6ee479d7c0a77&v=4
608660982,ChuanhuChatGPT,GaiZhenbiao/ChuanhuChatGPT,Python,6803,GUI for ChatGPT API and any LLM,1321,9131,https://avatars.githubusercontent.com/u/51039745?u=accb33fa417f386eaf9fc9b2ed07ec74fb36ada3&v=4
393874035,RWKV-LM,BlinkDL/RWKV-LM,Python,3090,"RWKV is an RNN with transformer-level LLM performance. It can be directly trained like a GPT (parallelizable). So it's combining the best of RNN and transformer - great performance, fast inference, saves VRAM, fast training, ""infinite"" ctx_len, and free sentence embedding.",372,5603,https://avatars.githubusercontent.com/u/33809201?u=430f11d99770a999b7b2461156c6eb02454b9869&v=4
589831718,ComfyUI,comfyanonymous/ComfyUI,Python,2938,A powerful and modular stable diffusion GUI with a graph/nodes interface.,433,4910,https://avatars.githubusercontent.com/u/121283862?u=9da8fb664b2e873abf1f117e172d33bce1ed55db&v=4
599320067,langflow,logspace-ai/langflow,Python,4302,"‚õìÔ∏è LangFlow is a UI for LangChain, designed with react-flow to provide an effortless way to experiment and prototype flows.",369,4838,https://avatars.githubusercontent.com/u/85702467?v=4
521021013,GLM-130B,THUDM/GLM-130B,Python,2011,GLM-130B: An Open Bilingual Pre-Trained Model (ICLR 2023),317,4422,https://avatars.githubusercontent.com/u/48590610?v=4
590604203,shell_gpt,TheR1D/shell_gpt,Python,2240,"A command-line productivity tool powered by ChatGPT, will help you accomplish your tasks faster and more efficiently.",271,4258,https://avatars.githubusercontent.com/u/16740832?u=b2923ac17fe6e2a7c9ea14800351ddb92f79b100&v=4
570384908,peft,huggingface/peft,Python,2683,ü§ó PEFT: State-of-the-art Parameter-Efficient Fine-Tuning.,281,4089,https://avatars.githubusercontent.com/u/25720743?v=4
581994080,Tune-A-Video,showlab/Tune-A-Video,Python,2184,Tune-A-Video: One-Shot Tuning of Image Diffusion Models for Text-to-Video Generation,237,2969,https://avatars.githubusercontent.com/u/101181824?v=4
580312797,self-instruct,yizhongw/self-instruct,Python,1231,Aligning pretrained language models with instruction data generated by themselves.,221,1810,https://avatars.githubusercontent.com/u/8654468?u=beb843110f32dee7211405170539b2829e1b61f2&v=4
589743600,chat-langchain,hwchase17/chat-langchain,Python,864,,367,1558,https://avatars.githubusercontent.com/u/11986836?u=f4c4f21a82b2af6c9f91e1f1d99ea40062f7a101&v=4
607474273,pyllama,juncongmoo/pyllama,Python,995,LLaMA: Open and Efficient Foundation Language Models,181,1538,https://avatars.githubusercontent.com/u/94136485?v=4
610307205,GPTQ-for-LLaMa,qwopqwop200/GPTQ-for-LLaMa,Python,865,4 bits quantization of LLaMA using GPTQ,221,1389,https://avatars.githubusercontent.com/u/64115820?v=4
574160606,chatgpt-telegram-bot,n3d1117/chatgpt-telegram-bot,Python,741,"ü§ñ A Telegram bot that integrates with OpenAI's official ChatGPT APIs to provide answers, written in Python",329,1149,https://avatars.githubusercontent.com/u/11541888?u=cddb84f41789bd51aab73687b71d293054187bfc&v=4
